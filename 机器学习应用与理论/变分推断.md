# 变分推断

好的，我们来从数学的角度，根据这篇论文的核心内容，讲解一下变分推断（Variational Inference, VI）。

**1. 核心问题：计算后验概率**

在贝叶斯统计中，我们通常关心的是在观测到数据 x 后，模型中未知的潜在变量（或参数）z 的**后验概率分布 p(z|x)**。根据贝叶斯定理：

p(z|x) = p(z, x) / p(x)

其中：

- p(z, x) 是 z 和 x 的联合概率分布，通常由模型定义，是可计算的。

- p(x) 是数据的边际概率（也称为证据，Evidence），计算方式是 p(x) = ∫ p(z, x) dz。

**困难之处**在于，对于许多现代复杂模型，计算 p(x) 这个积分非常困难，甚至在计算上是不可行的（intractable），因为它需要在 z 的所有可能取值（可能是高维空间）上进行积分。没有 p(x)，我们就无法精确计算后验 p(z|x)。

**2. VI 的核心思想：用优化逼近**

变分推断（VI）提出了一种不同的思路：**不去直接计算 p(z|x)，而是寻找一个容易处理的概率分布 q(z)，使其尽可能地“接近”真实的后验 p(z|x)。**

这个过程可以分解为以下数学步骤：

- **步骤 1：选择一个变分族 (Variational Family) Q**  
  我们首先定义一个**参数化**的概率分布族 Q。这个族中的每个分布 q(z; ν) 都由一组**变分参数 ν** 决定。选择 Q 的关键在于：
  
  - 它需要足够**灵活**，能够近似各种形状的后验分布。
  
  - 它需要足够**简单**，使得基于 q(z; ν) 的计算（如计算期望）是容易处理的。
  
  - 论文中重点介绍的是**平均场变分族 (Mean-Field Variational Family)**：假设 q(z) 可以分解为各个潜在变量 z_j (j=1 to m) 的独立分布的乘积：  
    q(z) = Π_{j=1}^m q_j(z_j; ν_j)  
    这极大地简化了计算，但代价是假设了后验分布中各变量是独立的（这通常只是近似）。

- **步骤 2：定义“接近度” - KL 散度**  
  我们使用 **Kullback-Leibler (KL) 散度**来衡量 q(z) 和 p(z|x) 之间的差异（或者说“距离”，虽然它不是严格意义上的距离）。目标是找到 Q 中使 KL 散度最小的那个 q(z)：  
  q*(z) = argmin_{q(z) ∈ Q} KL(q(z) || p(z|x))  
  KL 散度的定义是：  
  KL(q(z) || p(z|x)) = ∫ q(z) log( q(z) / p(z|x) ) dz = E_q[log q(z)] - E_q[log p(z|x)]  
  其中 E_q[...] 表示在 q(z) 分布下的期望。

- **步骤 3：优化 - ELBO**  
  直接最小化 KL(q(z) || p(z|x)) 仍然很困难，因为它里面包含了我们不知道的 p(z|x)。VI 的关键技巧在于引入和优化 **证据下界 (Evidence Lower Bound, ELBO)**。  
  我们可以把 KL 散度展开：  
  KL(q(z) || p(z|x)) = E_q[log q(z)] - E_q[log(p(z, x) / p(x))]  
  KL(q(z) || p(z|x)) = E_q[log q(z)] - E_q[log p(z, x)] + E_q[log p(x)]  
  因为 p(x) 不依赖于 z，E_q[log p(x)] = log p(x)。所以：  
  KL(q(z) || p(z|x)) = E_q[log q(z)] - E_q[log p(z, x)] + log p(x)  
  重新整理得到：  
  log p(x) = KL(q(z) || p(z|x)) + ( E_q[log p(z, x)] - E_q[log q(z)] )  
  我们定义括号里的项为 **ELBO(q)**：  
  ELBO(q) = E_q[log p(z, x)] - E_q[log q(z)]  
  因此：  
  log p(x) = KL(q(z) || p(z|x)) + ELBO(q)
  
  **关键洞察：**
  
  1. log p(x) 对于 q(z) 是一个常数。
  
  2. KL(q || p) ≥ 0。
  
  3. 所以 ELBO(q) 总是小于等于 log p(x)（这就是“下界”名称的由来）。
  
  4. **最小化 KL(q || p) 等价于最大化 ELBO(q)！**

  ELBO(q) 是可以计算的（假设在 q 下的期望可计算），因为它只依赖于已知的联合分布 p(z, x) 和我们选择的变分分布 q(z)。因此，VI 的目标从最小化 KL 散度转变为**最大化 ELBO**。

**3. 优化算法：坐标上升变分推断 (CAVI)**

对于平均场变分族 q(z) = Π q_j(z_j)，如何最大化 ELBO(q)？论文介绍了**坐标上升法 (Coordinate Ascent Variational Inference, CAVI)**。

CAVI 的思想是：**迭代地**优化**每一个**因子 q_j(z_j)，同时保持**其他**因子 q_l(z_l) (l ≠ j) 固定。

论文推导出（公式 17/18），保持其他因子固定时，最优的 q_j*(z_j) 满足：

log q_j*(z_j) = E_{q_{-j}}[log p(z_j | z_{-j}, x)] + constant

或者等价地（通常更容易计算）：

log q_j*(z_j) = E_{q_{-j}}[log p(z, x)] + constant

其中 E_{q_{-j}}[...] 表示对除了 z_j 之外的所有 z_l (l ≠ j) 在它们当前的变分分布 q_l(z_l) 下求期望。

这个更新规则告诉我们 q_j*(z_j) 的函数形式。如果模型具有良好的结构（比如论文后面讨论的指数族和条件共轭），这个期望通常可以解析计算，并且 q_j*(z_j) 会属于一个已知的分布族（例如高斯分布、Gamma 分布等），我们只需要更新它的参数即可。

CAVI 算法不断地循环更新每个 q_j(z_j)，直到 ELBO 收敛到一个局部最优值。

**总结**

从数学角度看，变分推断是一种**基于优化的近似推断方法**：

1. **目标：** 用简单的、参数化的分布 q(z; ν) 去逼近复杂、难解的后验 p(z|x)。

2. **度量：** 使用 KL 散度 KL(q || p) 衡量逼近程度。

3. **策略：** 通过最大化证据下界 ELBO(q) = E_q[log p(z, x)] - E_q[log q(z)] 来间接最小化 KL 散度。

4. **常用假设：** 平均场假设 q(z) = Π q_j(z_j) 简化计算。

5. **常用算法：** 坐标上升法 (CAVI) 迭代更新每个 q_j 的参数，直至 ELBO 收敛。

VI 的优点是速度通常比 MCMC 快，易于扩展到大规模数据集（尤其是随机变分推断 SVI，论文第 4.3 节），但缺点是它是近似方法，没有 MCMC 的渐近精确性保证，且平均场假设可能导致对后验方差的低估。
