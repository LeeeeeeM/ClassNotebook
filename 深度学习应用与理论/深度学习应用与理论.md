# 深度学习应用与理论

![image-20220901005058831](.\imgs\image-20220901005058831.png)

![image-test](/storage/dcim/Screenshots/Screenshot_20230724_230729_Edge.jpg)

## 主要关注什么

* 定制化的智能算法设计
* 图形学的/图像处理的
* 游戏AI
* 边缘设备的，多快好省的算法




## 应用

### U-net线稿上色模型

https://zhuanlan.zhihu.com/p/24712438



### 妆容迁移

https://zhuanlan.zhihu.com/p/426474467

### 纯数据驱动模型的调优
目标：数据接入和训练，验证的管道已经搭建好了。在这个基础之上想要优化模型训练的超参数，使得整个模型的构建过程自动化的同时又有尽可能高的预测精度。

#### 思路
* 对比不同的搜索算法,这里列举下我找到的搜索算法:
    * hyoeroarameter tuning
        * 随机搜索
        * 网格搜索
        * 贝叶斯优化
        * TPE
    * Neural Architecture Search
        * ENAS
        * DARTS
    * Early Stopping
        * Median Stop
* 黑盒视角
* 构建pipeline的成本不能过高

很多项目中超参调优用的都是网格搜索的方法，网格的方法本质上就是用组合的方法构造参数空间来逐个比较，会受到模型参数的约束，但简单暴力，在探索事件允许的情况下是个基本的思路。

这个问题的约束包括以下：
* 

#### 开源工具
* optuna
* skopt

#### FLAML理论分析
首先，FLAML本身支持的功能包括：
* 模型选择
* 超参调优
* Ensemble
* 推理参数调优

FLAML工具本身背后的理论支撑主要来源于微软的的Research小组

[Research](https://microsoft.github.io/FLAML/docs/Research)

##### 自动化优化流程
FLAML工具是面向任务的自动化AI工具，使用模式可分为：
* 拥有`fit`, `predict`两个核心API的estimator库，用户只需要提供训练数据以及任务类型，即可获得较优的机器学习模型
* 任务类型
    * 表式数据的分类以及回归
    * 时序数据预测
    * panel datasets时序预测
    * 排序
    * 序列分类
    * 序列回归

##### 预置模型，优化目标
首先用户可以自己提供需要的优化指标，Estimator，搜索空间
内置的优化指标包括如下：
* 1-accuracy
* log_loss（分类任务的默认指标）
* r2（回归使用的默认指标）
* 用户自定义指标函数（函数的入参和返回为约定接口，即可保证自定义的自由度和）

```python
def custom_metric(
    X_val, y_val, estimator, labels,
    X_train, y_train, weight_val=None, weight_train=None,
    config=None, groups_val=None, groups_train=None,
):
    return metric_to_minimize, metrics_to_log
```
回归主要采用的Estimator：
* lgbm
* xgboost
* xgb_limitdepth
* rf
* extra_tree

时序预测主要采用的Estimator：
* 所有回归的estimator
* prophet
* arima
* sarimax
* holt-winters
* temporal_fusion_transformer（panel时序预测）

##### Tunning过程
flaml的超参优化过程所采用的算法有两种：
* CFO
* BlendSearch

CFO使用$FLOW^2$方法来适应每一次优化的步长，搜索从对于计算而言低成本的点开始，逐步地转移到高成本的区域。

[CFO论文](arxiv.org/abs/2005.01571)


#### 实践
测试下列工具，以测试集的ACC和RMSE指标来衡量模型的好坏：
* Mindware(基于open-box)(似乎有些BUG)
* FLAML（似乎是维护的最好的）



## LLM-based应用

### 了解LangChain
文档中提到的核心动机：
* 连接LLM和数据源
* 允许语言模型和环境互动

安装langchain
```shell
pip install langchain[all]
# 依赖项非常多
```
langchain允许的组件包括这些:
* model I/O
* Data connection

使用代码




## 理论

